{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 2: SMPL-X Principle\n",
    "\n",
    "Author: [Hejia Chen](http://harryxd2018.github.io), BUAA\n",
    "\n",
    "In this tutorial, we will learn how to use SMPL-X model to generate a 3D human mesh.\n",
    "\n",
    "## Prerequisites"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import write_obj, load_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['dynamic_lmk_bary_coords', 'hands_componentsl', 'ft', 'lmk_faces_idx', 'f', 'J_regressor', 'hands_componentsr', 'kintree_table', 'hands_coeffsr', 'joint2num', 'hands_meanl', 'lmk_bary_coords', 'weights', 'posedirs', 'dynamic_lmk_faces_idx', 'part2num', 'vt', 'hands_meanr', 'hands_coeffsl', 'v_template', 'shapedirs'])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smplx_neutral = load_pkl('./models/smplx/SMPLX_NEUTRAL.pkl', to_torch=True)\n",
    "smplx_neutral.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Shape and expression control\n",
    "\n",
    "The SMPL-X model is parameterized by shape and expression parameters. The shape parameters control the body shape, while the expression parameters control the facial expression. The shape and expression parameters are 300-dimensional and 100-dimensional vectors, respectively. We can set the shape and expression parameters to zero to get the neutral body. The corresponding blendshapes will be added to the neutral body to generate the final mesh, which is stored as `shapedirs` of the SMPL-X model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapedirs dim: torch.Size([10475, 3, 400])\n"
     ]
    }
   ],
   "source": [
    "print('shapedirs dim:', smplx_neutral['shapedirs'].shape)\n",
    "\n",
    "betas = torch.zeros([1, 300], dtype=torch.float32)      # as the shape parameters\n",
    "psi = torch.zeros([1, 100], dtype=torch.float32)        # as the expression parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_deformation shape: torch.Size([10475, 3])\n",
      "expression_deformation shape: torch.Size([10475, 3])\n"
     ]
    }
   ],
   "source": [
    "shape_deformation = torch.sum(smplx_neutral['shapedirs'][..., :300] * betas, dim=-1)\n",
    "expression_deformation = torch.sum(smplx_neutral['shapedirs'][..., 300:] * psi, dim=-1)\n",
    "print(f\"shape_deformation shape: {shape_deformation.shape}\")\n",
    "print(f\"expression_deformation shape: {expression_deformation.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "new_vertice = smplx_neutral['v_template'] + shape_deformation + expression_deformation\n",
    "write_obj(vertices=new_vertice, faces=smplx_neutral['f'], file_name='./obj/smplx_neutral.obj')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of course, the result is expected to be a neutral body, because we haven't changed the parameters yet. Let's try to change the shape parameters to see what will happen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "betas[0, 0] = 1.0\n",
    "shape_deformation = torch.sum(smplx_neutral['shapedirs'][..., :300] * betas, dim=-1)\n",
    "expression_deformation = torch.sum(smplx_neutral['shapedirs'][..., 300:] * psi, dim=-1)\n",
    "new_vertice = smplx_neutral['v_template'] + shape_deformation + expression_deformation\n",
    "write_obj(vertices=new_vertice, faces=smplx_neutral['f'], file_name='./obj/smplx_tall.obj')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can see that the body is taller than the neutral body. We can also change the expression parameters to see what will happen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "psi[0, 0] = 1.0\n",
    "shape_deformation = torch.sum(smplx_neutral['shapedirs'][..., :300] * betas, dim=-1)\n",
    "expression_deformation = torch.sum(smplx_neutral['shapedirs'][..., 300:] * psi, dim=-1)\n",
    "new_vertice = smplx_neutral['v_template'] + shape_deformation + expression_deformation\n",
    "write_obj(vertices=new_vertice, faces=smplx_neutral['f'], file_name='./obj/smplx_smile.obj')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Pose deformation\n",
    "\n",
    "Body pose is also affecting the deformation of the body. In SMPL-X model, there are 55 joints, and each joint has 3 degrees of freedom. Therefore, the pose parameters `theta` are a 3x55 matrix. For each joint, the pose is represented under the rotation vector format. We can set the pose parameters to zero to get the T-pose body. The pose deformation blendshape are stored as `posedirs` of the SMPL-X model, which is corresponding to each element in the **rotaion matrix**. So to get the final pose deformation, we need to convert the rotation matrix to rotation vector first.\n",
    "\n",
    "For those who are not familiar with rotation vector, you can refer to following docs in Chinese:\n",
    "- [blog 1](https://zhuanlan.zhihu.com/p/451579313)\n",
    "- [blog 2](https://blog.csdn.net/Crystal_YS/article/details/103622853)\n",
    "- [blog 3](https://zhuanlan.zhihu.com/p/147791525)\n",
    "\n",
    "The conversion from rotation vector to rotation matrix is calculated by the **Rodrigues' rotation formula**:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def batch_rodrigues(\n",
    "    rot_vecs: torch.Tensor,\n",
    "    epsilon: float = 1e-8,\n",
    ") -> torch.Tensor:\n",
    "    ''' Calculates the rotation matrices for a batch of rotation vectors\n",
    "        Parameters\n",
    "        ----------\n",
    "        rot_vecs: torch.tensor Nx3\n",
    "            array of N axis-angle vectors\n",
    "        Returns\n",
    "        -------\n",
    "        R: torch.tensor Nx3x3\n",
    "            The rotation matrices for the given axis-angle parameters\n",
    "    '''\n",
    "\n",
    "    batch_size = rot_vecs.shape[0]\n",
    "    device, dtype = rot_vecs.device, rot_vecs.dtype\n",
    "\n",
    "    angle = torch.norm(rot_vecs + 1e-8, dim=1, keepdim=True)\n",
    "    rot_dir = rot_vecs / angle\n",
    "\n",
    "    cos = torch.unsqueeze(torch.cos(angle), dim=1)\n",
    "    sin = torch.unsqueeze(torch.sin(angle), dim=1)\n",
    "\n",
    "    # Bx1 arrays\n",
    "    rx, ry, rz = torch.split(rot_dir, 1, dim=1)\n",
    "    K = torch.zeros((batch_size, 3, 3), dtype=dtype, device=device)\n",
    "\n",
    "    zeros = torch.zeros((batch_size, 1), dtype=dtype, device=device)\n",
    "    K = torch.cat([zeros, -rz, ry, rz, zeros, -rx, -ry, rx, zeros], dim=1) \\\n",
    "        .view((batch_size, 3, 3))\n",
    "\n",
    "    ident = torch.eye(3, dtype=dtype, device=device).unsqueeze(dim=0)\n",
    "    rot_mat = ident + sin * K + (1 - cos) * torch.bmm(K, K)\n",
    "    return rot_mat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can get the pose deformation blendshape:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose_feature shape:  torch.Size([1, 486])\n"
     ]
    }
   ],
   "source": [
    "theta = torch.zeros([1, 55, 3], dtype=torch.float32)\n",
    "batch_size = theta.shape[0]\n",
    "ident = torch.eye(3, dtype=torch.float32)\n",
    "rot_mats = batch_rodrigues(theta.reshape(-1, 3)).reshape(batch_size, -1, 3, 3)\n",
    "pose_feature = (rot_mats[:, 1:, :, :] - ident).reshape(batch_size, -1)\n",
    "print('pose_feature shape: ', pose_feature.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pose_feature is a 468-dimensional vector, obtained as 9*(55+1), which is corresponding to the pose deformation blendshape. We can get the final pose deformation by multiplying the pose_feature with the posedirs:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose_deformation shape:  torch.Size([10475, 3])\n"
     ]
    }
   ],
   "source": [
    "pose_deformation = torch.sum(smplx_neutral['posedirs'] * pose_feature, dim=-1)\n",
    "print('pose_deformation shape: ', pose_deformation.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "new_vertice = smplx_neutral['v_template']  + pose_deformation\n",
    "write_obj(vertices=new_vertice, faces=smplx_neutral['f'], file_name='./obj/smplx_tpose.obj')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now lets try to change the pose parameters to see what will happen. Before that, the index of each joint is stored as:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array({'L_Middle3': 30, 'R_Wrist': 21, 'R_Foot': 11, 'Jaw': 22, 'L_Eye': 23, 'Spine1': 3, 'Spine3': 9, 'Spine2': 6, 'R_Thumb1': 52, 'R_Thumb3': 54, 'R_Thumb2': 53, 'R_Elbow': 19, 'Head': 15, 'L_Collar': 13, 'R_Hip': 2, 'R_Eye': 24, 'L_Ring1': 34, 'L_Ring2': 35, 'L_Ring3': 36, 'L_Thumb3': 39, 'L_Thumb2': 38, 'L_Thumb1': 37, 'R_Ring2': 50, 'R_Ring3': 51, 'R_Ring1': 49, 'L_Index3': 27, 'L_Index2': 26, 'L_Index1': 25, 'R_Shoulder': 17, 'Neck': 12, 'L_Foot': 10, 'R_Index1': 40, 'R_Index3': 42, 'R_Index2': 41, 'L_Knee': 4, 'L_Elbow': 18, 'R_Middle3': 45, 'R_Middle2': 44, 'R_Middle1': 43, 'L_Pinky1': 31, 'L_Pinky2': 32, 'L_Pinky3': 33, 'L_Middle1': 28, 'R_Ankle': 8, 'R_Collar': 14, 'L_Middle2': 29, 'R_Pinky2': 47, 'L_Wrist': 20, 'R_Pinky3': 48, 'L_Shoulder': 16, 'L_Hip': 1, 'R_Knee': 5, 'Pelvis': 0, 'R_Pinky1': 46, 'L_Ankle': 7},\n      dtype=object)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smplx_neutral['joint2num']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "theta = torch.zeros([1, 55, 3], dtype=torch.float32)\n",
    "theta[0, 15, 0] = torch.pi/6\n",
    "batch_size = theta.shape[0]\n",
    "ident = torch.eye(3, dtype=torch.float32)\n",
    "rot_mats = batch_rodrigues(theta.reshape(-1, 3)).reshape(batch_size, -1, 3, 3)\n",
    "pose_feature = (rot_mats[:, 1:, :, :] - ident).reshape(batch_size, -1)\n",
    "pose_deformation = torch.sum(smplx_neutral['posedirs'] * pose_feature, dim=-1)\n",
    "new_vertice = smplx_neutral['v_template'] + pose_deformation\n",
    "write_obj(vertices=new_vertice, faces=smplx_neutral['f'], file_name='./obj/smplx_tpose_1.obj')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the 15th joint is the head, and we rotate it by 30 degrees. The body is now in a T-pose. But the mesh in neck part is slightly different from the original one.\n",
    "\n",
    "<img src='images/2_pose_deformation.png' width='80%'>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Mesh transformation\n",
    "By now we only have a T-pose body, and we need to transform it to the target pose. The transformation is done by the **linear blend skinning** (LBS) algorithm. The LBS algorithm is a widely used method to deform the mesh. The basic idea is to use the transformation of the joints to deform the mesh.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "new_vertice = new_vertice.unsqueeze(0)              # BxNx3 -> BxNx3x1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joints shape:  torch.Size([1, 55, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "joints = torch.einsum('bik,ji->bjk', [new_vertice, smplx_neutral['J_regressor']])\n",
    "joints = torch.unsqueeze(joints, dim=-1)            # BxNx3 -> BxNx3x1\n",
    "print('joints shape: ', joints.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can get the transformation matrix of each joint by the rotation matrix and translation vector:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def transform_mat(R: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    ''' Creates a batch of transformation matrices\n",
    "        Args:\n",
    "            - R: Bx3x3 array of a batch of rotation matrices\n",
    "            - t: Bx3x1 array of a batch of translation vectors\n",
    "        Returns:\n",
    "            - T: Bx4x4 Transformation matrix\n",
    "    '''\n",
    "    # No padding left or right, only add an extra row\n",
    "    return torch.cat([torch.nn.functional.pad(R, [0, 0, 0, 1]),\n",
    "                      torch.nn.functional.pad(t, [0, 0, 0, 1], value=1)], dim=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "rel_joints = joints.clone()                         # BxNx3x1\n",
    "rel_joints[:, 1:] -= joints[:, smplx_neutral['kintree_table'][0][1:]]         # vector pointing from parent joint to child joint, translation\n",
    "\n",
    "transforms_mat = transform_mat(\n",
    "    rot_mats.reshape(-1, 3, 3),                     # BxNx3x3 -> (BxN)x3x3\n",
    "    rel_joints.reshape(-1, 3, 1)                    # BxNx3x1 -> (BxN)x3x1\n",
    ").reshape(-1, joints.shape[1], 4, 4)                # (BxN)x4x4 -> BxNx4x4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have the transformation matrix of each joint, and we can get the global transformation matrix of each joint by multiplying the transformation matrix of the parent joint. The global transformation matrix of the root joint is the identity matrix. The global transformation matrix of the other joints can be calculated as:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "transform_chain = [transforms_mat[:, 0]]            # Bx4x4 as the global transformation\n",
    "for i in range(1, smplx_neutral['kintree_table'][0].shape[0]):\n",
    "    # Subtract the joint location at the rest pose\n",
    "    # No need for rotation, since it's identity when at rest\n",
    "    curr_res = torch.matmul(transform_chain[smplx_neutral['kintree_table'][0][i]],\n",
    "                            transforms_mat[:, i])\n",
    "    transform_chain.append(curr_res)\n",
    "transforms = torch.stack(transform_chain, dim=1)    # BxNx4x4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last column of the transformations contains the posed joints, and the homogeneous coordinates of the posed joints can be obtained by padding the joints with 1. The relative transformation matrix of each joint can be calculated as:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "posed_joints = transforms[:, :, :3, 3]              # BxNx3\n",
    "\n",
    "joints_homogen = torch.nn.functional.pad(joints, [0, 0, 0, 1])        # BxNx3x1\n",
    "\n",
    "rel_transforms = transforms - torch.nn.functional.pad(\n",
    "    torch.matmul(transforms, joints_homogen), [3, 0, 0, 0, 0, 0, 0, 0])     # BxNx4x4\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we can get the posed mesh by applying the relative transformation matrix to the neutral mesh. For each vertex, we need to calculate the weighted sum of the relative transformation matrix of the joints that affect it. The weight of each joint is stored in the `weights` tensor. The final posed mesh can be calculated as:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "W = smplx_neutral['weights'].unsqueeze(dim=0).expand([batch_size, -1, -1])\n",
    "num_joints = smplx_neutral['J_regressor'].shape[0]\n",
    "T = torch.matmul(W, rel_transforms.view(batch_size, num_joints, 16)) \\\n",
    "        .view(batch_size, -1, 4, 4)\n",
    "homogen_coord = torch.ones([batch_size, new_vertice.shape[1], 1])\n",
    "v_posed_homo = torch.cat([new_vertice, homogen_coord], dim=2)\n",
    "v_homo = torch.matmul(T, torch.unsqueeze(v_posed_homo, dim=-1))\n",
    "\n",
    "verts = v_homo[:, :, :3, 0]\n",
    "write_obj(vertices=verts.squeeze(0), faces=smplx_neutral['f'], file_name='obj/smplx_look_down.obj')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By far, we can manipulate the SMPL-X body model on our own, check out the final pose:\n",
    "<img src='./images/2_pose_look_down.png' width='400px'>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
